** Some comments and outputs from my side**

Task 1:
    - working with the module argparse -- command-line parsing library
    - added a new parameter by using method add_argument(). This parameter allows the user to select
        the subset of tests to be run through a comma-separated list.
    - user must list the names of the tests without extensions, they are added to the files' names later on

Task 2:
    - created a new class -- child-class of the ExperimentConfiguration class -- (model_building folder)
    - used Keras for creating Neural Network
    - added new technique for Neural Network into enumeration in _experiment_configuration_.py
    - creation of the model happens in the build_model() method
    -

Task 3:
    - added support to explore number of epochs and batch-size through the configuration file,


Task 4:
    - added support for the topology specification,
    i.e. added support for depth, width, activation functions of the neural network, specified by the user
    -

Task 5:
    - Instead of dumping the entire model object using pickle, I should save it to a file (as a byte stream) using the respective deep learning framework's
    serialization method, and then dump the file contents using pickle
    - When loading the model, I first load the byte content from the pickle file, then restore the model using keras' load methos
    - worked with _get-state_ and _set_state_ methods for serialization (in the neural_network_experiment_configuration file)
    - The model is saved in HDF5 format using the Keras-provided save method.
    - The load_model method ensures that the model is only loaded if the file exists. If the file is missing, it raises a FileNotFoundError.